{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0230cdb",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3112b58",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89d6c7",
   "metadata": {},
   "source": [
    "We begin by importing the necessary libraries for data manipulation, visualization, preprocessing, and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89499fc7",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a283e26",
   "metadata": {},
   "source": [
    "The dataset contains transaction details. We load it using Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f40824",
   "metadata": {},
   "source": [
    "## Step 3: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3f567d",
   "metadata": {},
   "source": [
    "We check for missing values and analyze the class distribution to identify any imbalance in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b453bf",
   "metadata": {},
   "source": [
    "## Step 4: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632b66c",
   "metadata": {},
   "source": [
    "We visualize the transaction amount distribution and feature correlation using heatmaps and boxplots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3c884",
   "metadata": {},
   "source": [
    "## Step 5: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20b959",
   "metadata": {},
   "source": [
    "Feature scaling is applied to normalize the transaction amount, and unnecessary columns are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258a085",
   "metadata": {},
   "source": [
    "## Step 6: Splitting Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438718d",
   "metadata": {},
   "source": [
    "The dataset is split into training (80%) and testing (20%) sets to evaluate the model effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59186790",
   "metadata": {},
   "source": [
    "## Step 7: Train XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace28c0f",
   "metadata": {},
   "source": [
    "We train an XGBoost classifier on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9106ed2",
   "metadata": {},
   "source": [
    "## Step 8: Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97221d",
   "metadata": {},
   "source": [
    "The trained model is used to make predictions on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bdf9c2",
   "metadata": {},
   "source": [
    "## Step 9: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2761d",
   "metadata": {},
   "source": [
    "Performance is assessed using the classification report, confusion matrix, and ROC-AUC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aef23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load dataset\n",
    "data_df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfe3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Exploration\n",
    "print(\"Missing Values:\")\n",
    "print(data_df.isnull().sum())\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(data_df[\"Class\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "sns.countplot(x=\"Class\", data=data_df)\n",
    "plt.title(\"Class Distribution (0 = Not Fraud, 1 = Fraud)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Visualization\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data_df['Amount'], bins=50, kde=True)\n",
    "plt.title(\"Transaction Amount Distribution\")\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data_df.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x='Class', y='Amount', data=data_df)\n",
    "plt.title(\"Transaction Amount by Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Data Preprocessing\n",
    "scaler = StandardScaler()\n",
    "data_df['normAmount'] = scaler.fit_transform(data_df['Amount'].values.reshape(-1, 1))\n",
    "data_df = data_df.drop(['Time', 'Amount'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Splitting dataset into training and test sets\n",
    "X = data_df.drop(\"Class\", axis=1)\n",
    "y = data_df[\"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efe563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train XGBoost model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Model Predictions\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97315a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Model Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: AUC-ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
